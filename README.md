# multimodal-fewshot-frozen-learnin-models
This project explores how to perform few-shot learning across multiple data modalities (e.g., text + images) using frozen large language models. Inspired by models like CLIP and Flamingo.
![Few-Shot Accuracy Chart](images/few_shot_accuracy_chart.png)
